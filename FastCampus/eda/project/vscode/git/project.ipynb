{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c435c6d8",
   "metadata": {},
   "source": [
    "## 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a750ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete cell\n",
    "import pandas as pd\n",
    "\n",
    "import nltk \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ee0bf9",
   "metadata": {},
   "source": [
    "## pip install \n",
    "- 필요시 마크다운 해제 후 사용"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9cfa4623",
   "metadata": {},
   "source": [
    "nltk.download('all') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b799c382",
   "metadata": {},
   "source": [
    "## Option\n",
    "- 1. 출력 셀 전체 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce653a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710d2c16",
   "metadata": {},
   "source": [
    "- 2. 출력 셀 전체 보기 해제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c8ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_columns')\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481c5d42",
   "metadata": {},
   "source": [
    "## 파일 불러오기\n",
    "- 1. 'cs.' 으로 시작하는 카테고리 (arxiv data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b09588",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1_path= 'vscode/arxiv_cs.csv'\n",
    "docs1 = pd.read_csv(docs1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0266c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebeaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2_path = 'vscode/paperswithcode.csv'\n",
    "docs2 = pd.read_csv(docs2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd75da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs3_path = 'vscode/modified.csv'\n",
    "docs3 = pd.read_csv(docs3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341af09",
   "metadata": {},
   "source": [
    "- Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a123f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs4 = docs1.head(10000)\n",
    "docs4.to_csv('vscode/test_arxiv_cs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85686a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bfad57",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs5_path = 'vscode/modified.csv'\n",
    "docs5 = pd.read_csv(docs5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780aaff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs5.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8e6b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = docs5[['is_Computer Vision', 'is_Natural Language Processing', 'is_Reinforcement Learning', 'is_Audio','is_Sequential', 'is_Graph']].sum(axis=1)\n",
    "true_count_least2 = len(docs5[true_count >= 3])\n",
    "true_count_least2\n",
    "\n",
    "#rf'\\b\\d*{process_model_name(tmp_model)}s?\\d*\\b' -> 2908 257 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd999cf",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "### 목적\n",
    "- 1) title & abstract의 키워드를 통해 categories 예측\n",
    "    - 방법1) tokenizing -> 각 카테고리별 빈도수 높은 단어 추출\n",
    "    - 방법2) paperswithcode의 카테고리별 모델명 불러오기\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7136d3db",
   "metadata": {},
   "source": [
    "### 1. 데이터 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e007ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1. head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d951ad0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs1.isnull().sum()\n",
    "# 결측치 다수 : comments, journal-ref, doi, report-no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20faf452",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f85a13",
   "metadata": {},
   "source": [
    "### 2. tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441293e7",
   "metadata": {},
   "source": [
    "1) cs.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9496f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_ai_docs = docs1[docs1['categories'].str.contains('cs.AI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b738ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_ai_docs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c88cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_ai_abstract = cs_ai_docs.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ced8d6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize를 통한 abstract의 corpus 추출\n",
    "tokenized_cs_ai_abstract = [nltk.word_tokenize(i) for i in cs_ai_abstract]\n",
    "tokenized_cs_ai_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571436af",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_tokens = []\n",
    "stop_words = set(stopwords.words('english')) # 불용어 제거\n",
    "\n",
    "for abstract_tokens in tokenized_cs_ai_abstract:\n",
    "    # isalnum() : 숫자&문자 \n",
    "    # 불용어가 아니고 숫자&문자로 이뤄진 단어만 추출\n",
    "    cleaned_tokens = [token.lower() for token in abstract_tokens if token.isalnum() and token.lower() not in stop_words]\n",
    "    filtered_tokens.extend(cleaned_tokens)\n",
    "\n",
    "# 단어별 빈도수 계산\n",
    "counter = Counter(filtered_tokens)\n",
    "most_common_words = counter.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fd77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결론 \n",
    "# tokenize로 유의미한 결과를 도출할 수 없다.\n",
    "# -> 해당 결과로 category를 분류하기엔 무리가 있다고 판단"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3270ff",
   "metadata": {},
   "source": [
    "### 3. 모델에 따른 카테고리화 ex. VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6dc8b6",
   "metadata": {},
   "source": [
    "1) cs.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10ff2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract에서 VGG(대소문자 구분X)를 포함하는 행 찾기\n",
    "filtered_cs_ai_docs = cs_ai_docs[cs_ai_docs['abstract'].str.contains(re.compile(\"VGG\", re.I))]\n",
    "display(len(cs_ai_docs))\n",
    "display(len(filtered_cs_ai_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e9f033",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = filtered_cs_ai_docs.loc[:,\"abstract\"]\n",
    "tmp.iloc[0]\n",
    "# 해당 구문에 VGGNET 이 들어가 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56df73b",
   "metadata": {},
   "source": [
    "2) cs.CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87f241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_cv_docs = docs1[docs1['categories'].str.contains('cs.CV')]\n",
    "filtered_cs_cv_docs = cs_cv_docs[cs_cv_docs['abstract'].str.contains(re.compile(\"VGG\", re.I))]\n",
    "len(filtered_cs_cv_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3efec2",
   "metadata": {},
   "source": [
    "3) cs.DM (Discrete Mathmatics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed316967",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_dm_docs = docs1[docs1['categories'].str.contains('cs.DM')]\n",
    "filtered_cs_dm_docs = cs_dm_docs[cs_dm_docs['abstract'].str.contains(re.compile(\"VGG\", re.I))]\n",
    "len(filtered_cs_dm_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bcb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결론 \n",
    "# tokenize(방법1)에 비해 유의미한 결론을 도출할 수 있었음\n",
    "# 대분류, 즉 CV와 NLP에서 사용하는 모델은 차이가 있기에 분류 기준으로서 적합하다고 판단\n",
    "# paperswithcode의 카테고리별 모델을 불러와서 위의 코드를 실행해도 좋을 듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f271073",
   "metadata": {},
   "source": [
    "### 4. 모델에 따른 카테고리화 ex. VGG, ResNet, AlexNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456c7ff2",
   "metadata": {},
   "source": [
    "1) cs.AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbcb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 리스트\n",
    "model_list = [\"Resnet\", \"VGG\", \"AlexNet\"]\n",
    "\n",
    "model_counts = defaultdict(int)\n",
    "\n",
    "for model in model_list:\n",
    "    pattern = re.compile(model, re.I)\n",
    "    filtered_docs = cs_ai_docs[cs_ai_docs['abstract'].str.contains(pattern)]\n",
    "    model_counts[model] = len(filtered_docs) # key : value\n",
    "\n",
    "for model, count in model_counts.items():\n",
    "    print(f\"{model}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc99fb4",
   "metadata": {},
   "source": [
    "2) cs.CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3220e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 리스트\n",
    "model_list = [\"Resnet\", \"VGG\", \"AlexNet\"]\n",
    "\n",
    "model_counts = defaultdict(int)\n",
    "\n",
    "for model in model_list:\n",
    "    pattern = re.compile(model, re.I)\n",
    "    filtered_docs = cs_cv_docs[cs_cv_docs['abstract'].str.contains(pattern)]\n",
    "    model_counts[model] = len(filtered_docs) # key : value\n",
    "\n",
    "for model, count in model_counts.items():\n",
    "    print(f\"{model}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818df67",
   "metadata": {},
   "source": [
    "3) cs.DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a1b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 리스트\n",
    "model_list = [\"Resnet\", \"VGG\", \"AlexNet\"]\n",
    "\n",
    "model_counts = defaultdict(int)\n",
    "\n",
    "for model in model_list:\n",
    "    pattern = re.compile(model, re.I)\n",
    "    filtered_docs = cs_dm_docs[cs_dm_docs['abstract'].str.contains(pattern)]\n",
    "    model_counts[model] = len(filtered_docs) # key : value\n",
    "\n",
    "for model, count in model_counts.items():\n",
    "    print(f\"{model}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85832110",
   "metadata": {},
   "source": [
    "### 5. paperswithcode dataset (크롤링)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b019d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "1. see all categories (click) \n",
    "    기존 : (6,3) : general 제외, graph 예외처리 \n",
    "    변경 : (4,3)클릭 위치 변경을 통한 예외를 없애줌 \n",
    "<기존>\n",
    "body > div.container > div.container.content.content-buffer > div.infinite-container.featured-methods > div:nth-child(6) > a    \n",
    "    \n",
    "<변경>\n",
    "body > div.container > div.container.content.content-buffer > div.infinite-container.featured-methods > div:nth-child(4) > div > h4 > a\n",
    "body > div.container > div.container.content.content-buffer > div.infinite-container.featured-methods > div:nth-child(7) > div > h4 > a\n",
    "\n",
    "\n",
    "2. method (고정값)\n",
    "body > div.container.content.content-buffer > div > div.title.browse-methods-title > div:nth-child(2) > div > h1\n",
    "\n",
    "\n",
    "3. see all models (click)\n",
    "    (3,3)\n",
    "\n",
    "body > div.container.content.content-buffer > div > div.infinite-container.featured-methods > div:nth-child(3) > a\n",
    "\n",
    "4. categories (고정값)\n",
    "body > div.container.content.content-buffer > div.mobile-width > div.artefact-header > h1\n",
    "\n",
    "5. models\n",
    "    (1,1) : category에 해당하는 모델이 없는 경우(예외 처리)\n",
    "    #methodsTable > tbody > tr:nth-child(1) > td:nth-child(1) > div.method-image > a\n",
    "    #methodsTable > tbody > tr:nth-child(2) > td:nth-child(1) > div.method-image > a\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df4c2fd",
   "metadata": {},
   "source": [
    "- Main Code (주석 해제 후 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb54e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://paperswithcode.com/methods')\n",
    "data_list = []  \n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "tmp1=4\n",
    "while True: # 1,2번   \n",
    "    try:\n",
    "        click1_selector = f'body > div.container > div.container.content.content-buffer > div.infinite-container.featured-methods > div:nth-child({tmp1}) > div > h4 > a'\n",
    "        temp_categories = driver.find_element(By.CSS_SELECTOR,click1_selector) #\n",
    "    except NoSuchElementException:       \n",
    "            break\n",
    "    driver.execute_script(\"arguments[0].click();\", temp_categories)\n",
    "    tmp1 +=3\n",
    "    time.sleep(1.5)\n",
    "    \n",
    "    # 클릭으로 인한 페이지 업데이트\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    method_selector = 'body > div.container.content.content-buffer > div > div.title.browse-methods-title > div:nth-child(2) > div > h1'\n",
    "    method_name = soup.select(method_selector)\n",
    "    if not method_name:\n",
    "        break\n",
    "    method = method_name[0].text.strip().replace('\\n','')\n",
    "    print('method: ',method)\n",
    "    \n",
    "    tmp2 = 3\n",
    "    while True: # 3,4번\n",
    "        try:\n",
    "            click2_selector = f'body > div.container.content.content-buffer > div > div.infinite-container.featured-methods > div:nth-child({tmp2}) > a'\n",
    "            temp_model = driver.find_element(By.CSS_SELECTOR,click2_selector)\n",
    "        except NoSuchElementException: \n",
    "            break\n",
    "        driver.execute_script(\"arguments[0].click();\", temp_model)\n",
    "        tmp2 += 3\n",
    "        time.sleep(1.5)\n",
    "        \n",
    "        # 페이지 업데이트\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        #here\n",
    "        category_selector = 'body > div.container.content.content-buffer > div.mobile-width > div.artefact-header > h1'\n",
    "        category_name = soup.select(category_selector)\n",
    "        if not category_name:\n",
    "            break\n",
    "        category = category_name[0].text.split(\"\\xa0\")[0].strip()\n",
    "        print('category: ',category)\n",
    "\n",
    "        model_list = []\n",
    "        tmp3 = 1\n",
    "        while True: # 5번\n",
    "            model_selector = f'#methodsTable > tbody > tr:nth-child({tmp3}) > td:nth-child(1) > div.method-image > a'\n",
    "            model_name = soup.select(model_selector) \n",
    "            if not model_name:\n",
    "                break\n",
    "            model = model_name[0].text.strip().replace('\\n', '')\n",
    "            model_list.append(model)\n",
    "            print(\"model: \",model)\n",
    "            tmp3 += 1\n",
    "            \n",
    "        data_list.append([method,category,', '.join(model_list)])\n",
    "        \n",
    "        driver.back()\n",
    "    driver.back()\n",
    "\n",
    "# 데이터를 CSV 파일로 저장\n",
    "with open('cw_paperswithcode.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['method', 'category', 'model'])  # 헤더 추가\n",
    "    csv_writer.writerows(data_list)  # 데이터 추가\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e076385",
   "metadata": {},
   "source": [
    "- csv 구조 변경 (행열 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d16a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# 입력 파일과 출력 파일 이름\\\n",
    "input_filename = r'C:\\Users\\ASUS\\Desktop\\coding\\FastCampus\\eda\\project\\vscode\\cw_paperswithcode.csv'\n",
    "output_filename = r'C:\\Users\\ASUS\\Desktop\\coding\\FastCampus\\eda\\project\\vscode\\paperswithcode.csv'\n",
    "# CSV 파일을 읽고 데이터를 리스트로 저장\n",
    "data = []\n",
    "with open(input_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "\n",
    "# 데이터를 풀어서 저장할 새로운 리스트 생성\n",
    "unrolled_data = []\n",
    "for row in data:\n",
    "    method = row[0]\n",
    "    category = row[1]\n",
    "    models = row[2].split(', ')  # ,를 기준으로 model들을 분리\n",
    "    for model in models:\n",
    "        unrolled_data.append([method, category, model])\n",
    "\n",
    "# 새로운 CSV 파일로 데이터를 쓰기\n",
    "with open(output_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    for row in unrolled_data:\n",
    "        csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4522dcc",
   "metadata": {},
   "source": [
    "### 6. 모델 리스트 불러오기 (paperswithcode.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d365e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2_path = 'vscode/paperswithcode.csv'\n",
    "docs2 = pd.read_csv(docs2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be082d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2.info() #model 2개 null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733cbc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78724b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8911e4",
   "metadata": {},
   "source": [
    "### 7. 모델 리스트를 패턴화하여 arxiv dataset에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef74b1ea",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = docs2[docs2.method.str.contains('Computer Vision')]\n",
    "model_list = tmp.iloc[:,2].tolist() #모델\n",
    "\n",
    "model_counts = defaultdict(int) # key : value\n",
    "patterns={}\n",
    "\n",
    "# 패턴화 하기\n",
    "for model in model_list:\n",
    "    if isinstance(model,str): # model 의 객체가 string 이면\n",
    "        patterns[model] = re.compile(re.escape(model),re.I)\n",
    "\n",
    "# document filtering\n",
    "filtered_cs_cv_docs = {model: cs_cv_docs[cs_cv_docs['abstract'].str.contains(pattern)] \n",
    "                      for model,pattern in patterns.items()}\n",
    "\n",
    "for model,filtered_docs in filtered_cs_cv_docs.items():\n",
    "    model_counts[model] = len(filtered_docs)\n",
    "\n",
    "for model,count in model_counts.items():\n",
    "    print(f\"{model} : {count}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b51bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결론\n",
    "# 생각했던 것에 비해 model_counts의 값이 작다.\n",
    "# 정규표현식을 통한 대소문자 구분 및 문자열 구분 등을 확장하여 개선해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d92bc",
   "metadata": {},
   "source": [
    "### 8. 정규표현식을 이용하여 7번의 결과를 개선하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec253ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=\"VGG\"\n",
    "\n",
    "# CASE1 -> GAN : 대소문자 구분 x & 문자열 구분 x -> legan, lovegan (0)\n",
    "matching_rows1 = cs_cv_docs[\n",
    "    cs_cv_docs['abstract'].str.contains(re.compile(f\"{tmp}\", re.I))| #정규표현식 re.I -> 대소문자 구별X\n",
    "    cs_cv_docs['title'].str.contains(re.compile(f\"{tmp}\", re.I))\n",
    "]\n",
    "matching_count1 = len(matching_rows1)\n",
    "print(matching_count1)\n",
    "\n",
    "\n",
    "# CASE2 -> 대소문자 구분 o & 문자열 구분 o -> GAN(o) eGAN(x)\n",
    "\n",
    "matching_rows2 = cs_cv_docs[\n",
    "    cs_cv_docs['abstract'].str.contains(rf'\\b{tmp}\\b')|\n",
    "    cs_cv_docs['title'].str.contains(rf'\\b{tmp}\\b')\n",
    "]\n",
    "matching_count2 = len(matching_rows2)\n",
    "print(matching_count2)\n",
    "\n",
    "\n",
    "# CASE3 -> 대소문자 구분 x & 문자열 구분 o -> GAN & gan (o) -> 영진님 \n",
    "   \n",
    "matching_rows3 = cs_cv_docs[\n",
    "    cs_cv_docs['abstract'].str.contains(re.compile(rf'\\b{tmp}\\b',re.I))|\n",
    "    cs_cv_docs['title'].str.contains(re.compile(rf'\\b{tmp}\\b',re.I))\n",
    "]\n",
    "matching_count3 = len(matching_rows3)\n",
    "print(matching_count3)\n",
    "\n",
    "\n",
    "#CASE4 -> 대소문자 구분 o & 문자열 구분x -> eGAN (o) egan(x)\n",
    "\n",
    "matching_rows4 = cs_cv_docs[\n",
    "    cs_cv_docs['abstract'].str.contains(f\"{tmp}\")|\n",
    "    cs_cv_docs['title'].str.contains(f\"{tmp}\")\n",
    "]\n",
    "matching_count4 = len(matching_rows4)\n",
    "print(matching_count4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c032b46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "<정리 CASE1-4>\n",
    "1. 대소문자를 구분하지 않아야 함\n",
    "    UNET,uNet,UNet\n",
    "\n",
    "2. 문자열 구분은 애매함\n",
    "\n",
    "2-1) 문자열 구분을 하면(2,3) 모델의 폭이 줄어들음 -> GAN) DCGAN, StyleGAN 불가\n",
    "하지만 paperswithcode의 모델리스트가 어느정도 커버가 되긴 한다. \n",
    "\n",
    "2-2) 문자열 구분을 하지 않으면(1,4) 모델의 폭이 증가하나 CCT모델의 경우 CCTV 단어도 인식을 하기에 리스크가 크다.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07be6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE5 -> 대소문자 구분 x & 문자열 구분 * -> 공백 및 숫자 인정 -> ResNet, ResNet 1 , ResNet1 \n",
    "\n",
    "matching_rows5 = cs_cv_docs[\n",
    "    cs_cv_docs['abstract'].str.contains(re.compile(rf'\\b\\d*\\s*{tmp}\\s*\\d*\\b',re.I))|\n",
    "    cs_cv_docs['title'].str.contains(re.compile(rf'\\b\\d*\\s*{tmp}\\s*\\d*\\b',re.I))\n",
    "]\n",
    "matching_count5 = len(matching_rows5)\n",
    "print(matching_count5)\n",
    "\n",
    "\n",
    "# CASE6 -> 대소문자 구분 x & 문자열 구분 * -> 공백 및 숫자 인정 + 's' 인정 -> GANs, VGGs \n",
    "\n",
    "matching_rows6 = cs_cv_docs[\n",
    "    cs_cv_docs['abstract'].str.contains(re.compile(rf'\\b\\d*\\s*{tmp}s?\\s*\\d*\\b',re.I))|\n",
    "    cs_cv_docs['title'].str.contains(re.compile(rf'\\b\\d*\\s*{tmp}s?\\s*\\d*\\b',re.I))\n",
    "]\n",
    "matching_count6 = len(matching_rows6)\n",
    "print(matching_count6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213fcab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "<정리 CASE5-6>\n",
    "1. 대소문자는 구분하지 않아야 함.\n",
    "2. 문자열은 일부 구분\n",
    "    공백 및 숫자는 허용하도록 함. -> VGG19\n",
    "3. 모델+'s' 허용\n",
    "    Abstract 분석 결과 GANs, VGGs 로 표기된 경우도 다수 있었음\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b07f227",
   "metadata": {},
   "source": [
    "### 9. model_list (paperswithcode) + title & abstract (arxiv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58415a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84007a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs3[docs3['is_Reinforcement Learning']==True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0586924f",
   "metadata": {},
   "source": [
    "- 중복 칼럼 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = docs3[['is_Computer Vision', 'is_Natural Language Processing', 'is_Reinforcement Learning', 'is_Audio','is_Sequential', 'is_Graph']].sum(axis=1)\n",
    "true_count_least2 = len(docs3[true_count >= 2])\n",
    "true_count_least2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3c6e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = docs3[['is_Computer Vision', 'is_Natural Language Processing', 'is_Reinforcement Learning', 'is_Audio','is_Sequential', 'is_Graph']].sum(axis=1)\n",
    "true_count_least3 = len(docs3[true_count >= 3])\n",
    "true_count_least3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = docs3[['is_Computer Vision', 'is_Natural Language Processing', 'is_Reinforcement Learning', 'is_Audio','is_Sequential', 'is_Graph']].sum(axis=1)\n",
    "true_count_least4 = len(docs3[true_count >= 4])\n",
    "true_count_least4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = docs3[['is_Computer Vision', 'is_Natural Language Processing', 'is_Reinforcement Learning', 'is_Audio','is_Sequential', 'is_Graph']].sum(axis=1)\n",
    "true_count_least5 = len(docs3[true_count >= 5])\n",
    "true_count_least5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffccc720",
   "metadata": {},
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4807eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s1 = pd.Series(['house and parrot'])\n",
    "\n",
    "tmp = 'parrot'\n",
    "print(s1.str.contains(rf\"\\b{tmp}\\b\", case=False))\n",
    "print(s1.str.match(rf'\\b\\d\\s*{tmp_model}s?\\s*\\d*\\b', case=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7296bb1",
   "metadata": {},
   "source": [
    "### IDEA (detail)\n",
    "- 1) 중복되는 카테고리 처리는?\n",
    "ex. Transformer 모델의 경우 CV인지 NLP인지 구분해줄 필요가 있을 것 같음.\n",
    "- 2) journal-ref를 활용해볼까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1fc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmp_docs=pd.read_csv('vscode/modified.csv')\n",
    "\n",
    "tmp_docs.rename(columns={'is_Computer Vision': 'is_CV', 'is_Natural Language Processing': 'is_NLP',\n",
    "                  'is_Reinforcement Learning':'is_RL','is_Audio':'is_Au','is_Sequential':'is_Se','is_Graphs':'is_Gr'}, inplace=True)\n",
    "\n",
    "# 변경된 DataFrame을 CSV 파일로 저장\n",
    "tmp_docs.to_csv('vscode/modified1.csv', index=False)  # index=False로 설정하여 인덱스 열을 저장하지 않도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f992d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_docs = pd.read_csv('vscode/modified1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117689c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_docs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fbff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_count = tmp_docs[['is_CV','is_NLP','is_RL','is_Au','is_Se','is_Gr']].sum(axis=1)\n",
    "true_count_least2 = len(tmp_docs[true_count >= 5])\n",
    "true_count_least2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d57385e",
   "metadata": {},
   "source": [
    "### categories(arxiv)와 method(paperswithcode) 간의 관계 분석\n",
    "\n",
    "- CV -> cs.AI, cs.CV\n",
    "- NLP -> cs.AI, cs.CL\n",
    "- RL -> cs.LG\n",
    "- Au -> cs.SD\n",
    "- Se -> \n",
    "- Gr -> cs.DM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e3cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories= ['AI','AR','CC','CE','CG','CL','CR',\n",
    "              'CV','CY','DB','DC','DL','DM','DS',\n",
    "              'ET','FL','GL','GR','GT','HC','IR',\n",
    "              'IT','LG','LO','MA','MM','MS','NA',\n",
    "              'NE','NI','OH','OS','PF','PL','RO',\n",
    "              'SC','SD','SE','SI','SY'] #40개\n",
    "\n",
    "methods =['CV','NLP','RL','Au','Se','Gr']\n",
    "\n",
    "result_dict={}\n",
    "for method in methods:\n",
    "    cnt_dict={}\n",
    "    for category in categories:\n",
    "        cnt_dict[category]=len(tmp_docs[(tmp_docs[f'is_{method}']==True) & (tmp_docs['categories'].str.contains(f'cs.{category}'))])\n",
    "    result_dict[method] = sorted(cnt_dict.items(), key=lambda x: x[1],reverse=True) # value값 기준"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868054c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e30a7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "<영진님 -> data_ai_fin2.csv>\n",
    "Method: CV, Count: 37016\n",
    "Category: CV, ratio: 57.77%\n",
    "Category: LG, ratio: 46.67%\n",
    "Category: AI, ratio: 19.21%\n",
    "----------------------------\n",
    "Method: NLP, Count: 67224\n",
    "Category: LG, ratio: 45.31%\n",
    "Category: CV, ratio: 36.47%\n",
    "Category: CL, ratio: 26.18%\n",
    "----------------------------\n",
    "Method: RL, Count: 4603\n",
    "Category: LG, ratio: 63.5%\n",
    "Category: AI, ratio: 43.34%\n",
    "Category: CV, ratio: 18.86%\n",
    "----------------------------\n",
    "Method: Au, Count: 257\n",
    "Category: SD, ratio: 58.75%\n",
    "Category: LG, ratio: 57.2%\n",
    "Category: CL, ratio: 45.14%\n",
    "----------------------------\n",
    "Method: Se, Count: 4908\n",
    "Category: LG, ratio: 47.78%\n",
    "Category: CL, ratio: 47.05%\n",
    "Category: CV, ratio: 22.43%\n",
    "----------------------------\n",
    "Method: Gr, Count: 15711\n",
    "Category: CV, ratio: 46.1%\n",
    "Category: LG, ratio: 43.42%\n",
    "Category: AI, ratio: 24.52%\n",
    "----------------------------\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10eabc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['CV','NLP','RL','Au','Se','Gr']\n",
    "method_count = [len(tmp_docs[tmp_docs[f'is_{method}']==True]) for method in methods]              \n",
    "\n",
    "i=0    \n",
    "for method in methods:                \n",
    "    top_categories = result_dict[method][:3] \n",
    "    print(f\"Method: {method}, Count: {method_count[i]}\")\n",
    "    for category, category_count in top_categories:\n",
    "        #print(f\"Category: {category}, Count: {category_count}\")\n",
    "        print(f\"Category: {category}, ratio: {round(category_count/method_count[i]*100,2)}%\")\n",
    "    i+=1\n",
    "    print('----------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e055cf36",
   "metadata": {},
   "source": [
    "### CV와 NLP에서 중복되는 모델 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aa62c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method가 'a'인 행과 'b'인 행을 따로 추출합니다.\n",
    "method_cv = docs[docs2['method'] == 'Computer Vision']\n",
    "method_nlp = docs2[docs2['method'] == 'Natural Language Processing']\n",
    "\n",
    "common_models = pd.merge(method_cv, method_nlp, on='model', how='inner') #model이 같은 행만 추출\n",
    "display(common_models)\n",
    "\n",
    "common_model_count = len(common_models)\n",
    "display(common_model_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddadfc12",
   "metadata": {},
   "source": [
    "#### Abstract & Title 에 TNT,MHMA,GEE,ViLBERT,ClipBERT가 포함된 행의 개수 출력해보기 (정규표현식 유지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85167a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict={}\n",
    "models=['TNT','MHMA','GEE','ViLBERT','ClipBERT']\n",
    "for model in tqdm(models):\n",
    "    if isinstance(model, str):\n",
    "        pattern = rf'\\b\\d*{model}s?\\d*\\b'\n",
    "        tmp_df = docs1['abstract'].str.contains(pattern,case=False,regex=True) | docs1['title'].str.contains(pattern,case=False,regex=True) \n",
    "        test_dict[model]=len(tmp_df[tmp_df==True]) #tmp_df : pd.Series\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1aa446",
   "metadata": {},
   "source": [
    "-> 이렇게 적은데,, 왜 NLP에서 cs.CV와 LG가 겹치냐고..왜"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
